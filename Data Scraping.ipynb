{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# randomized delay between requests as a consideration to Reddit's servers and security staff \n",
        "# run this cell \n",
        "\n",
        "import requests \n",
        "import time \n",
        "import pandas as pd \n",
        "from random import randint "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "url = \"https://www.reddit.com/r/stress.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "headers = {\"User-agent\" : \"randuser\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# functions to automate the data collection process \n",
        "def reddit_scrape(url_string, number_of_scrapes, output_list):\n",
        "  after = None \n",
        "  for _  in range(number_of_scrapes):\n",
        "    if _ == 0:\n",
        "      print(f\"SCRAPING {url_string}\\n--------------------------------------------------\")\n",
        "      print(\"<<<SCRAPING COMMENCED>>>\")\n",
        "      print(f\"Downloading Batch {1} of {number_of_scrapes}\")\n",
        "    elif (_+1) % 5 == 0:\n",
        "      print(f\"Downloading batch {(_ + 1)} of {number_of_scrapes}\")\n",
        "\n",
        "    if after == None:\n",
        "      params = {} \n",
        "    else:\n",
        "      # tells the scraper to get the next set after reddit's after code \n",
        "      params = {\"after\": after}\n",
        "    res = requests.get(url_string, params=params, headers=headers)\n",
        "    if res.status_code == 200:\n",
        "      the_json = res.json() \n",
        "      output_list.extend(the_json[\"data\"][\"children\"])\n",
        "      after = the_json[\"data\"][\"after\"]\n",
        "    else:\n",
        "      print(res.status_code)\n",
        "      break \n",
        "    time.sleep(randint(1,6))\n",
        "\n",
        "  print(\"<<<SCRAPING COMPLETED>>>\")\n",
        "  print(f\"Number of posts downloaded: {len(output_list)}\")\n",
        "  print(\"Number of unique posts: {}\".format(len(set([p[\"data\"][\"name\"] for p in output_list]))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCRAPING https://www.reddit.com/r/stress.json\n",
            "--------------------------------------------------\n",
            "<<<SCRAPING COMMENCED>>>\n",
            "Downloading Batch 1 of 100\n",
            "Downloading batch 5 of 100\n",
            "Downloading batch 10 of 100\n",
            "Downloading batch 15 of 100\n",
            "Downloading batch 20 of 100\n",
            "Downloading batch 25 of 100\n",
            "Downloading batch 30 of 100\n",
            "Downloading batch 35 of 100\n",
            "Downloading batch 40 of 100\n",
            "Downloading batch 45 of 100\n",
            "Downloading batch 50 of 100\n",
            "Downloading batch 55 of 100\n",
            "Downloading batch 60 of 100\n",
            "Downloading batch 65 of 100\n",
            "Downloading batch 70 of 100\n",
            "Downloading batch 75 of 100\n",
            "Downloading batch 80 of 100\n",
            "Downloading batch 85 of 100\n",
            "Downloading batch 90 of 100\n",
            "Downloading batch 95 of 100\n",
            "Downloading batch 100 of 100\n",
            "<<<SCRAPING COMPLETED>>>\n",
            "Number of posts downloaded: 2480\n",
            "Number of unique posts: 818\n"
          ]
        }
      ],
      "source": [
        "# call the function \n",
        "stress_scraped = [] \n",
        "# 50 batches of 26\n",
        "reddit_scrape(\"https://www.reddit.com/r/stress.json\", 100, stress_scraped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function that scrapes the data \n",
        "def create_unique_list(original_scrape_list, new_list_name):\n",
        "  data_name_list =[] \n",
        "  for i in range(len(original_scrape_list)):\n",
        "    # name is the unique name assigned to each post \n",
        "    # if the name of the post is not already in data_name_list \n",
        "    # then add it to the new_list_name \n",
        "    if original_scrape_list[i][\"data\"][\"name\"] not in data_name_list:\n",
        "      new_list_name.append(original_scrape_list[i][\"data\"])\n",
        "      data_name_list.append(original_scrape_list[i][\"data\"][\"name\"])\n",
        "  print(f\"List now contains {len(new_list_name)} unique scraped posts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "List now contains 818 unique scraped posts\n"
          ]
        }
      ],
      "source": [
        "stress_scraped_unique = [] \n",
        "create_unique_list(stress_scraped, stress_scraped_unique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# putting the data into a dataframe saving to csv \n",
        "stress = pd.DataFrame(stress_scraped_unique)\n",
        "# naively assign stress label to every post \n",
        "stress[\"is_stress\"] = 1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# stress.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "url_conspiracy = \"https://www.reddit.com/r/conspiracy.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SCRAPING https://www.reddit.com/r/conspiracy.json\n",
            "--------------------------------------------------\n",
            "<<<SCRAPING COMMENCED>>>\n",
            "Downloading Batch 1 of 100\n",
            "Downloading batch 5 of 100\n",
            "Downloading batch 10 of 100\n",
            "Downloading batch 15 of 100\n",
            "Downloading batch 20 of 100\n",
            "Downloading batch 25 of 100\n",
            "Downloading batch 30 of 100\n",
            "Downloading batch 35 of 100\n",
            "Downloading batch 40 of 100\n",
            "Downloading batch 45 of 100\n",
            "Downloading batch 50 of 100\n",
            "Downloading batch 55 of 100\n",
            "Downloading batch 60 of 100\n",
            "Downloading batch 65 of 100\n",
            "Downloading batch 70 of 100\n",
            "Downloading batch 75 of 100\n",
            "Downloading batch 80 of 100\n",
            "Downloading batch 85 of 100\n",
            "Downloading batch 90 of 100\n",
            "Downloading batch 95 of 100\n",
            "Downloading batch 100 of 100\n",
            "<<<SCRAPING COMPLETED>>>\n",
            "Number of posts downloaded: 2482\n",
            "Number of unique posts: 943\n"
          ]
        }
      ],
      "source": [
        "conspiracy_scraped = []\n",
        "reddit_scrape(url_conspiracy, 100, conspiracy_scraped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "List now contains 943 unique scraped posts\n"
          ]
        }
      ],
      "source": [
        "consp_scraped_unique = []\n",
        "create_unique_list(conspiracy_scraped, consp_scraped_unique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "conspiracy = pd.DataFrame(consp_scraped_unique)\n",
        "conspiracy[\"is_stress\"] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# stress, anxiety, homeless, assistance, food, casual, conspiracy, jokes, med \n",
        "\n",
        "stress_columns = stress[[\"title\", \"selftext\", \"author\",  \"num_comments\", \"is_stress\",\"url\"]]\n",
        "consp_columns = conspiracy[[\"title\", \"selftext\", \"author\",  \"num_comments\", \"is_stress\",\"url\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_data = pd.concat([stress_columns, consp_columns], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_data[\"selftext\"].fillna(\"emptypost\",inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>selftext</th>\n",
              "      <th>author</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>is_stress</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Free Covid-19 Anxiety e-Workbook. Please, take...</td>\n",
              "      <td>The book is available [Here](https://thewellne...</td>\n",
              "      <td>Impudence</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.reddit.com/r/Stress/comments/fwes8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Any tips to breathe deeply? I'm always short b...</td>\n",
              "      <td></td>\n",
              "      <td>kind-sofa</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.reddit.com/r/Stress/comments/ubu69...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Just realized I’ve forgotten a lot of things f...</td>\n",
              "      <td></td>\n",
              "      <td>yanshixo</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.reddit.com/r/Stress/comments/ublh6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Self employed business stress. Slowly eating m...</td>\n",
              "      <td>I’m a 2021 graduate. I went straight into bein...</td>\n",
              "      <td>Ok-kitsunekitty</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.reddit.com/r/Stress/comments/ubhs0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stressed out</td>\n",
              "      <td>Honestly I just need to tell someone like bruh...</td>\n",
              "      <td>AppointmentNo2153</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>https://www.reddit.com/r/Stress/comments/ubaea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  \\\n",
              "0  Free Covid-19 Anxiety e-Workbook. Please, take...   \n",
              "1  Any tips to breathe deeply? I'm always short b...   \n",
              "2  Just realized I’ve forgotten a lot of things f...   \n",
              "3  Self employed business stress. Slowly eating m...   \n",
              "4                                       Stressed out   \n",
              "\n",
              "                                            selftext             author  \\\n",
              "0  The book is available [Here](https://thewellne...          Impudence   \n",
              "1                                                             kind-sofa   \n",
              "2                                                              yanshixo   \n",
              "3  I’m a 2021 graduate. I went straight into bein...    Ok-kitsunekitty   \n",
              "4  Honestly I just need to tell someone like bruh...  AppointmentNo2153   \n",
              "\n",
              "   num_comments  is_stress                                                url  \n",
              "0            11          1  https://www.reddit.com/r/Stress/comments/fwes8...  \n",
              "1             5          1  https://www.reddit.com/r/Stress/comments/ubu69...  \n",
              "2             2          1  https://www.reddit.com/r/Stress/comments/ublh6...  \n",
              "3             0          1  https://www.reddit.com/r/Stress/comments/ubhs0...  \n",
              "4             4          1  https://www.reddit.com/r/Stress/comments/ubaea...  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "title           0\n",
              "selftext        0\n",
              "author          0\n",
              "num_comments    0\n",
              "is_stress       0\n",
              "url             0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "818"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# dataframe[dataframe['Percentage'] > 80]\n",
        "len(combined_data[combined_data['is_stress'] == 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "943"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(combined_data[combined_data['is_stress'] == 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_data.to_csv('combined.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10    I really have no idea what my next step. 100% ...\n",
              "Name: selftext, dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_data.iloc[[10]][\"selftext\"]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Unsupervised Label Correction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "702",
      "language": "python",
      "name": "702"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
