{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8859,"status":"ok","timestamp":1650371198199,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"XRneXAqpaBWQ"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/svetlana.maslenkova/.conda/envs/nlp_project_env/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, f1_score\n","import transformers\n","from transformers import AutoModel, BertTokenizerFast\n","\n","# specify GPU\n","device = torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1650371198203,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"-EUQl6zW05Et","outputId":"099bed63-32c7-40a8-d538-9af9b4273469"},"outputs":[{"name":"stdout","output_type":"stream","text":["PyTorch Version:  1.11.0+cu102\n","Torchvision Version:  0.12.0+cu102\n"]}],"source":["from __future__ import print_function\n","from __future__ import division\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","print(\"PyTorch Version: \",torch.__version__)\n","print(\"Torchvision Version: \",torchvision.__version__)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":372,"status":"ok","timestamp":1650371199934,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"BTr-OGfVb_yj","outputId":"004e0935-1105-47c6-faa0-1ff081e04f0d"},"outputs":[{"data":{"text/plain":["'/home/svetlana.maslenkova/Documents/nlp_project'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import os, sys\n","\n","cwd = os.getcwd()\n","cwd"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1650371850679,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"qqJIX9KdcIkw"},"outputs":[],"source":["TRAIN_DATA_PATH = cwd + '/data/dreaddit-train.csv'\n","TEST_DATA_PATH = cwd + '/data/dreaddit-test.csv'\n","CORRECTED_LABELS_DATA_PATH = cwd + '/data/reddit-scraped.csv'\n","\n","PRETRAINED_FSJ_EMB_UNFREEZE_MODEL_PATH = cwd + '/checkpoints/pretrained_FSJ_lstm_lr0.00005_emb_unfreeze.pt'\n","\n","DREDDIT_FT_MODEL_PATH = cwd + '/checkpoints/full_ekman_ft_dreddit_ft.pt'\n","\n","# best_model_ft = '/content/drive/MyDrive/MBZUAI/NLP702/project/checkpoints/best_model_ft.pt'"]},{"cell_type":"markdown","metadata":{},"source":["# Data preprocessing"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":298},"executionInfo":{"elapsed":1480,"status":"ok","timestamp":1650371211599,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"qR7zZjY3cUYc","outputId":"9964ff0d-cd41-4f75-fef7-1c2bd9f31498"},"outputs":[{"name":"stdout","output_type":"stream","text":["shape of the train dataset:  (2838, 2)\n","number of positve samples:  1488\n","number of negative samples:  1350\n","the ratio of neg to pos:  0.91\n","shape of the test dataset:  (715, 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>He said he had not felt that way before, sugge...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hey there r/assistance, Not sure if this is th...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>My mom then hit me with the newspaper and it s...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>until i met my new boyfriend, he is amazing, h...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>October is Domestic Violence Awareness Month a...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label\n","0  He said he had not felt that way before, sugge...      1\n","1  Hey there r/assistance, Not sure if this is th...      0\n","2  My mom then hit me with the newspaper and it s...      1\n","3  until i met my new boyfriend, he is amazing, h...      1\n","4  October is Domestic Violence Awareness Month a...      1"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["train_data = pd.read_csv(TRAIN_DATA_PATH)\n","test_data = pd.read_csv(TEST_DATA_PATH)\n","data = train_data[['text', 'label']].copy()\n","test_data = test_data[['text', 'label']].copy()\n","print('shape of the train dataset: ', data.shape)\n","print('number of positve samples: ', data[data.label==1].shape[0])\n","print('number of negative samples: ', data[data.label==0].shape[0])\n","print('the ratio of neg to pos: ', np.round(data[data.label==0].shape[0]/data[data.label==1].shape[0], 2))\n","print('shape of the test dataset: ', test_data.shape)\n","data.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":305,"status":"ok","timestamp":1650371224700,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"PI0u2pWAc8-V","outputId":"1a27b9e1-c57c-452f-fc5d-4b16e32e58bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["max number of words:  310\n"]}],"source":["data['WORD_COUNT'] = data['text'].apply(lambda x: len(x.split()))\n","max_len = np.max(data.WORD_COUNT.values)\n","print('max number of words: ', max_len)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"elapsed":1012,"status":"ok","timestamp":1650371227541,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"HKW1attzfCdY","outputId":"c7e4e724-cc60-4810-fd75-4d48b4ff6d09"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["from matplotlib import pyplot as plt\n","\n","plt.hist(data['WORD_COUNT'], 100, density=False, facecolor='g', alpha=0.75)\n","\n","plt.xlabel('n of words')\n","plt.ylabel('n od samples')\n","plt.title('Number of words in Dreddit posts')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1650371251329,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"wPQfcNcEMPcb","outputId":"3a104809-1f46-4fe9-a858-228212a88d09"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>WORD_COUNT</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>He said he had not felt that way before, sugge...</td>\n","      <td>1</td>\n","      <td>113</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hey there r/assistance, Not sure if this is th...</td>\n","      <td>0</td>\n","      <td>108</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label  WORD_COUNT\n","0  He said he had not felt that way before, sugge...      1         113\n","1  Hey there r/assistance, Not sure if this is th...      0         108"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["data.head(2)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":309,"status":"ok","timestamp":1650371260524,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"XIMnIbmTMFSZ"},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","\n","class Stress_FT_Dataset(Dataset):\n","\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.text = dataframe['text']\n","        self.targets = self.data.label\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, index):\n","        text = str(self.text[index])\n","        text = \" \".join(text.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n","        }"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["c79c1c688b3c4f7389cf76a934a82378","f204f4c79e254cbaa96f05c9b018fa67","0b0ed811216543588b38c137c57b3331","34ca726ad7104c88ad979a79a889cca5","6882de94e1ab42a38e1761bb8838367c","94f8545622c24e30bcc7bc9f69b01a9b","21708d51fbbf4664b43daee248f1c2b7","fe54b5efc1094e8aa48940a111abcdc8","e0f5e55da36c471d91d98a96c6f83837","e5d6e0e75db74ef8a89a9f49ed44e19d","4bd2c1e3293c43908f6546007511ea7f","391e7c39a37341118b86821139598815","1ff0a0a64a6d4c33aad012a633857d07","316fae4b9cf74be693eb4c49c64d6bdf","5d147280bd0741398aa0119eada21d07","eb2e425ab2de4e7a9e0acb5dd8596f46","29d4de607d0649c4a26c61a14bfd6b85","15ef4a18ff8749b3931af3855934268e","01005edc168f4540b7e46c7907e80c67","66e6b4fd40ea4b8583f72a52a515d98d","9193860e7e9a484982d2f3b45ed534e6","8827f1e845a04a2e8295a3d39c08cfc7","b8df008871184250a97b5a125784e05a","c086868fdf154110b8c2db89ea369bec","5387bc93b7c24dc38c8fb27e19694983","aae4e04292b24eb3945bfdb2c861137b","eff42d7ed4c64a6baf5362580a57d687","b5bfa525f3a54e1e9d1b3ec0d35c7a22","63e7ec0056354dd892bbe31f6aa9312f","d93692a3055e43e2a9e0edba051196a2","9925a1b9341a41ba8cf4cea751de3a7f","905691cc49b94b349248fd2807862d63","0f731478802344a2b9c3962de8184b8b"]},"executionInfo":{"elapsed":1847,"status":"ok","timestamp":1650371275196,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"0fId4Hk7MzqR","outputId":"23881410-28e4-42ba-b259-f6cde5ad9940"},"outputs":[],"source":["from transformers import BertTokenizer\n","# Defining some key variables that will be used later on in the training\n","MAX_LEN = 200\n","EPOCHS = 50\n","LEARNING_RATE = 1e-05\n","num_classes = 2\n","batch_size = 100\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":287,"status":"ok","timestamp":1650371279417,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"gmUcrKrAMZYQ","outputId":"d2146cb8-9d33-48ef-f32b-1c2bd06f92ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["FULL Dataset: (2838, 3)\n","TRAIN Dataset: (2128, 3)\n","VALID Dataset: (710, 3)\n","TEST Dataset: (715, 2)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","train_dataset, valid_dataset = train_test_split(data, random_state=42, test_size = 0.25)\n","valid_dataset = valid_dataset.reset_index(drop=True)\n","train_dataset = train_dataset.reset_index(drop=True)\n","test_dataset = test_data.reset_index(drop=True)\n","\n","\n","print(\"FULL Dataset: {}\".format(data.shape))\n","print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","print(\"VALID Dataset: {}\".format(valid_dataset.shape))\n","print(\"TEST Dataset: {}\".format(test_dataset.shape))\n","\n","training_set = Stress_FT_Dataset(train_dataset, tokenizer, MAX_LEN)\n","validation_set = Stress_FT_Dataset(valid_dataset, tokenizer, MAX_LEN)\n","\n","train_loader = DataLoader(training_set, batch_size=batch_size , shuffle=True)\n","valid_loader = DataLoader(validation_set, batch_size=batch_size, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Functions"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":341,"status":"ok","timestamp":1650371314401,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"JLxlcrdES-pX"},"outputs":[],"source":["import shutil, sys   \n","def save_ckp(state, is_best, checkpoint_path):\n","    \"\"\"\n","    state: checkpoint we want to save\n","    is_best: is this the best checkpoint; min validation loss\n","    checkpoint_path: path to save checkpoint\n","    best_model_path: path to save best model\n","    \"\"\"\n","    f_path = checkpoint_path\n","    # save checkpoint data to the path given, checkpoint_path\n","    torch.save(state, f_path)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":304,"status":"ok","timestamp":1650371316959,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"NWlyIpD4hFo-"},"outputs":[],"source":["def loss_fn(outputs, targets):\n","    return torch.nn.CrossEntropyLoss()(outputs, targets)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":554,"status":"ok","timestamp":1650371855482,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"_2lYb2S817nL"},"outputs":[],"source":["def train_model(model, dataloaders, criterion, optimizer, checkpoint_path, num_epochs=15):\n","    since = time.time()\n","\n","    val_acc_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_f1 = 0.0\n","    # best_acc = 0.0\n","    wandb.watch(model)\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n","        print('-' * 10)\n","\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = {'train':0.0, 'val':0.0}\n","            running_corrects = {'train':0, 'val':0}\n","            epoch_avg_loss = {'train':0.0, 'val':0.0}\n","            epoch_avg_acc = {'train':0.0, 'val':0.0}\n","            epoch_loss_list = {'train':[], 'val':[]}\n","            epoch_acc_list = {'train':[], 'val':[]}\n","            epoch_f1_list = {'train':[], 'val':[]}\n","            global_step = 0\n","            global_steps_list = []\n","            stacked_labels = torch.tensor([]).to(device=device)\n","            stacked_preds = torch.tensor([]).to(device=device)\n","\n","\n","            # Iterate over data.\n","            for batch_idx, data in enumerate(dataloaders[phase]):\n","                ids = data['ids'].to(device, dtype = torch.long)\n","                mask = data['mask'].to(device, dtype = torch.long)\n","                token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","                labels = data['targets'].to(device, dtype = torch.long)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","                \n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    # Get model outputs and calculate loss\n","                    # In train mode we calculate the loss by summing the final output\n","                    # and the auxiliary output but in testing we only consider the final output.\n","                    \n","                    outputs = model(ids, mask, token_type_ids)\n","                    loss = criterion(torch.sigmoid(outputs), labels)\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","                        global_step += 1\n","                        wandb.log({'step_train_loss': loss.item(), 'global_step':global_step})\n","\n","                    stacked_labels = torch.cat([stacked_labels, labels])\n","                    stacked_preds = torch.cat([stacked_preds, preds])\n","\n","                    # statistics\n","                    running_loss[phase] += loss.item() # * labels.size(0)\n","                    running_corrects[phase] += torch.sum(preds == labels.data)\n","                    \n","\n","            epoch_avg_loss[phase] = running_loss[phase] / len(dataloaders[phase].dataset)\n","            epoch_avg_acc[phase] = running_corrects[phase].double() / len(dataloaders[phase].dataset)\n","            epoch_f1 = f1_score(stacked_labels.cpu(), stacked_preds.cpu())\n","            epoch_loss_list[phase].append(epoch_avg_loss[phase])\n","            epoch_acc_list[phase].append(epoch_avg_acc[phase])\n","            epoch_f1_list[phase].append(epoch_f1)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f} F1: {:.4f}'.format(phase, epoch_avg_loss[phase], epoch_avg_acc[phase], epoch_f1))\n","            \n","            # deep copy the model\n","            if phase == 'val' and epoch_f1 > best_f1:\n","                best_f1 = epoch_f1\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","            if phase == 'val':\n","                val_acc_history.append(epoch_avg_acc[phase])\n","                wandb.log({\"epoch_avg_loss_val\": epoch_avg_loss[phase], 'epoch_avg_acc_val':epoch_avg_acc[phase], \"epoch_f1\":epoch_f1, 'epoch':epoch+1})\n","            if phase == 'train':\n","                wandb.log({\"epoch_avg_loss_train\": epoch_avg_loss[phase], 'epoch_avg_acc_train':epoch_avg_acc[phase], 'epoch':epoch+1})\n","              \n","            running_loss[phase] = 0.0\n","            running_corrects[phase] = 0.0\n","        \n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    # print('Best val Acc: {:4f}'.format(best_acc))\n","    print('Best val F1: {:4f}'.format(best_f1))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","\n","    checkpoint = {\n","            'epoch': epoch + 1,\n","            'valid_loss_min': epoch_avg_loss['val'],\n","            'state_dict': model.state_dict(),\n","            'optimizer': optimizer.state_dict()\n","      }\n","\n","    # save checkpoint\n","    save_ckp(checkpoint, False, checkpoint_path)\n","    return model, val_acc_history"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":300,"status":"ok","timestamp":1650371446437,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"pAgkm6XT7KAQ"},"outputs":[],"source":["## model without LSRM layer\n","# class BERTClass(torch.nn.Module):\n","#     def __init__(self):\n","#         super(BERTClass, self).__init__()\n","#         self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n","#         self.l2 = torch.nn.Dropout(0.3)\n","#         self.l3 = torch.nn.Linear(768, 3)\n","    \n","#     def forward(self, ids, mask, token_type_ids):\n","#         _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n","#         output_2 = self.l2(output_1)\n","#         output = self.l3(output_2)\n","#         return output\n","\n","# baseline model\n","class BERTClass_Dreddit(torch.nn.Module):\n","    def __init__(self):\n","        super(BERTClass_Dreddit, self).__init__()\n","        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n","        self.l2 = torch.nn.Dropout(0.3)\n","        self.lstm = nn.LSTM(input_size=768,\n","                    hidden_size=128,\n","                    num_layers=1,\n","                    batch_first=True,\n","                    bidirectional=True)\n","        self.l3 = torch.nn.Linear(256, 2)\n","    \n","    def forward(self, ids, mask, token_type_ids):\n","        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n","        output = self.l2(output).unsqueeze(1)\n","        output, _ = self.lstm(output)\n","        output = self.l3(output).squeeze(1)\n","        return output\n","\n","class BERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(BERTClass, self).__init__()\n","        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict=False)\n","        self.l2 = torch.nn.Dropout(0.3)\n","        self.lstm = nn.LSTM(input_size=768,\n","                            hidden_size=128,\n","                            num_layers=1,\n","                            batch_first=True,\n","                            bidirectional=True)\n","        self.l3 = torch.nn.Linear(256, 3)\n","    \n","    def forward(self, ids, mask, token_type_ids):\n","        _, output= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n","        output = self.l2(output).unsqueeze(1)\n","        output, _ = self.lstm(output)\n","        output = self.l3(output).squeeze(1)\n","        return output\n","\n","model = BERTClass()"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":461,"status":"ok","timestamp":1650371475371,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"aXlu16-q6Kfz"},"outputs":[],"source":["def initialize_model(pretrained_path, num_classes, use_pretrained=True, gpu=False):\n","    # Initialize these variables which will be set in this if statement. Each of these\n","    #   variables is model specific.\n","    input_size = 0\n","    \n","    if gpu==True:\n","      map_location = torch.device('cuda')\n","    else:\n","      map_location = torch.device('cpu')\n","      \n","    model_ft = BERTClass()\n","    model_ft.load_state_dict(torch.load(pretrained_path, map_location=map_location)['state_dict'])\n","    num_ftrs = model_ft.l3.in_features\n","    model_ft.l3 = nn.Linear(num_ftrs, num_classes)\n","\n","    return model_ft, input_size\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1650371478801,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"1wIBAPLwNQYt","outputId":"7b5565f1-5c7c-4489-da32-b0e7b2098b27"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"C-9Nb8B7G3i1"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"text/plain":["BERTClass(\n","  (l1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (l2): Dropout(p=0.3, inplace=False)\n","  (lstm): LSTM(768, 128, batch_first=True, bidirectional=True)\n","  (l3): Linear(in_features=256, out_features=2, bias=True)\n",")"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize the model for this run\n","model_ft, input_size = initialize_model(PRETRAINED_FSJ_EMB_UNFREEZE_MODEL_PATH, num_classes, use_pretrained=True, gpu=False)\n","model_ft.to(device)\n","# Print the model we just instantiated\n","# print(model_ft)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gI3UlDVbIPu9"},"outputs":[],"source":["params_to_update = model_ft.parameters()\n","\n","## print model parameters\n","# for name, param in model_ft.named_parameters():   \n","#     print(\"\\t\",name, param.requires_grad)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1650374185427,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"4_vHKU0iRDOF"},"outputs":[],"source":["from torch.optim import Adam\n","\n","optimizer_ft = Adam(params_to_update, lr= LEARNING_RATE)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1650371533844,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"2i4gCHlCUwN4"},"outputs":[],"source":["dataloaders_dict = {}\n","dataloaders_dict['train'] = train_loader\n","dataloaders_dict['val'] = valid_loader"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["DREDDIT_FT_MODEL_PATH = '/home/svetlana.maslenkova/Documents/nlp_project/checkpoints/FT_FSJ_dreddit_ft_lr0.00005_emb_9_unfreeze.pt'"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2d4e7d02f6a949b6a054304affbbceb1","fafa7f1d1f6a431a8800d71a58225437","8a21bb5d6544469699db4688c79b8675","819bac1a67724f3981e558266864aa80","af08011d784943de8effbabe64f7b697","79231d87f06544bb9f46e58312c91094","25bd4f7f006246d3b5ceccd15080b5e3","9a11bc46c96a446587b672c206e248b4"]},"executionInfo":{"elapsed":1744185,"status":"ok","timestamp":1650375937464,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"C2Hwcma0R6Uw","outputId":"26e81e78-4b12-4a1d-a734-51cc43be2ce6"},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaslenkovas\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"data":{"text/html":["Tracking run with wandb version 0.12.15"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/svetlana.maslenkova/Documents/nlp_project/wandb/run-20220428_203232-2j797yg5</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/maslenkovas/nlp-project/runs/2j797yg5\" target=\"_blank\">FT_3_fullEkman_dreddit_ft_lr0.00005_emb_9_unfreeze</a></strong> to <a href=\"https://wandb.ai/maslenkovas/nlp-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","----------\n","train Loss: 0.0070 Acc: 0.6400 F1: 0.6924\n","val Loss: 0.0073 Acc: 0.7352 F1: 0.7679\n","\n","Epoch 2/50\n","----------\n","train Loss: 0.0065 Acc: 0.8022 F1: 0.8138\n","val Loss: 0.0070 Acc: 0.7535 F1: 0.8000\n","\n","Epoch 3/50\n","----------\n","train Loss: 0.0061 Acc: 0.8524 F1: 0.8632\n","val Loss: 0.0068 Acc: 0.7606 F1: 0.8005\n","\n","Epoch 4/50\n","----------\n","train Loss: 0.0057 Acc: 0.8849 F1: 0.8924\n","val Loss: 0.0065 Acc: 0.7789 F1: 0.8151\n","\n","Epoch 5/50\n","----------\n","train Loss: 0.0053 Acc: 0.9084 F1: 0.9145\n","val Loss: 0.0062 Acc: 0.7901 F1: 0.8198\n","\n","Epoch 6/50\n","----------\n","train Loss: 0.0050 Acc: 0.9309 F1: 0.9354\n","val Loss: 0.0061 Acc: 0.8014 F1: 0.8253\n","\n","Epoch 7/50\n","----------\n","train Loss: 0.0047 Acc: 0.9474 F1: 0.9506\n","val Loss: 0.0059 Acc: 0.7958 F1: 0.8221\n","\n","Epoch 8/50\n","----------\n","train Loss: 0.0045 Acc: 0.9601 F1: 0.9622\n","val Loss: 0.0061 Acc: 0.7958 F1: 0.8194\n","\n","Epoch 9/50\n","----------\n","train Loss: 0.0043 Acc: 0.9652 F1: 0.9671\n","val Loss: 0.0057 Acc: 0.8169 F1: 0.8354\n","\n","Epoch 10/50\n","----------\n","train Loss: 0.0042 Acc: 0.9718 F1: 0.9732\n","val Loss: 0.0060 Acc: 0.7972 F1: 0.8222\n","\n","Epoch 11/50\n","----------\n","train Loss: 0.0041 Acc: 0.9779 F1: 0.9790\n","val Loss: 0.0056 Acc: 0.8113 F1: 0.8321\n","\n","Epoch 12/50\n","----------\n","train Loss: 0.0040 Acc: 0.9807 F1: 0.9816\n","val Loss: 0.0057 Acc: 0.7972 F1: 0.8227\n","\n","Epoch 13/50\n","----------\n","train Loss: 0.0039 Acc: 0.9831 F1: 0.9839\n","val Loss: 0.0058 Acc: 0.7986 F1: 0.8237\n","\n","Epoch 14/50\n","----------\n","train Loss: 0.0039 Acc: 0.9840 F1: 0.9847\n","val Loss: 0.0057 Acc: 0.8085 F1: 0.8274\n","\n","Epoch 15/50\n","----------\n","train Loss: 0.0038 Acc: 0.9826 F1: 0.9834\n","val Loss: 0.0060 Acc: 0.7944 F1: 0.8211\n","\n","Epoch 16/50\n","----------\n","train Loss: 0.0039 Acc: 0.9756 F1: 0.9767\n","val Loss: 0.0060 Acc: 0.8042 F1: 0.8225\n","\n","Epoch 17/50\n","----------\n","train Loss: 0.0038 Acc: 0.9803 F1: 0.9811\n","val Loss: 0.0057 Acc: 0.8028 F1: 0.8237\n","\n","Epoch 18/50\n","----------\n","train Loss: 0.0037 Acc: 0.9831 F1: 0.9838\n","val Loss: 0.0057 Acc: 0.8056 F1: 0.8189\n","\n","Epoch 19/50\n","----------\n","train Loss: 0.0037 Acc: 0.9850 F1: 0.9856\n","val Loss: 0.0057 Acc: 0.8000 F1: 0.8203\n","\n","Epoch 20/50\n","----------\n","train Loss: 0.0037 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0056 Acc: 0.8028 F1: 0.8223\n","\n","Epoch 21/50\n","----------\n","train Loss: 0.0037 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0058 Acc: 0.8028 F1: 0.8214\n","\n","Epoch 22/50\n","----------\n","train Loss: 0.0036 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0057 Acc: 0.8014 F1: 0.8222\n","\n","Epoch 23/50\n","----------\n","train Loss: 0.0036 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0056 Acc: 0.8070 F1: 0.8277\n","\n","Epoch 24/50\n","----------\n","train Loss: 0.0036 Acc: 0.9859 F1: 0.9865\n","val Loss: 0.0056 Acc: 0.8183 F1: 0.8331\n","\n","Epoch 25/50\n","----------\n","train Loss: 0.0036 Acc: 0.9859 F1: 0.9865\n","val Loss: 0.0057 Acc: 0.8155 F1: 0.8348\n","\n","Epoch 26/50\n","----------\n","train Loss: 0.0036 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0057 Acc: 0.8183 F1: 0.8348\n","\n","Epoch 27/50\n","----------\n","train Loss: 0.0036 Acc: 0.9859 F1: 0.9865\n","val Loss: 0.0064 Acc: 0.7873 F1: 0.8187\n","\n","Epoch 28/50\n","----------\n","train Loss: 0.0036 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0057 Acc: 0.8141 F1: 0.8312\n","\n","Epoch 29/50\n","----------\n","train Loss: 0.0036 Acc: 0.9859 F1: 0.9865\n","val Loss: 0.0055 Acc: 0.8183 F1: 0.8327\n","\n","Epoch 30/50\n","----------\n","train Loss: 0.0036 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0061 Acc: 0.8113 F1: 0.8333\n","\n","Epoch 31/50\n","----------\n","train Loss: 0.0036 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0058 Acc: 0.8070 F1: 0.8290\n","\n","Epoch 32/50\n","----------\n","train Loss: 0.0035 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0057 Acc: 0.8141 F1: 0.8338\n","\n","Epoch 33/50\n","----------\n","train Loss: 0.0036 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0056 Acc: 0.8085 F1: 0.8296\n","\n","Epoch 34/50\n","----------\n","train Loss: 0.0035 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0056 Acc: 0.8085 F1: 0.8300\n","\n","Epoch 35/50\n","----------\n","train Loss: 0.0035 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0057 Acc: 0.8085 F1: 0.8291\n","\n","Epoch 36/50\n","----------\n","train Loss: 0.0035 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0057 Acc: 0.7944 F1: 0.8220\n","\n","Epoch 37/50\n","----------\n","train Loss: 0.0035 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0058 Acc: 0.8099 F1: 0.8254\n","\n","Epoch 38/50\n","----------\n","train Loss: 0.0035 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0062 Acc: 0.7873 F1: 0.8179\n","\n","Epoch 39/50\n","----------\n","train Loss: 0.0035 Acc: 0.9859 F1: 0.9865\n","val Loss: 0.0058 Acc: 0.8155 F1: 0.8314\n","\n","Epoch 40/50\n","----------\n","train Loss: 0.0035 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0055 Acc: 0.8113 F1: 0.8333\n","\n","Epoch 41/50\n","----------\n","train Loss: 0.0035 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0057 Acc: 0.8127 F1: 0.8344\n","\n","Epoch 42/50\n","----------\n","train Loss: 0.0035 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0056 Acc: 0.8099 F1: 0.8323\n","\n","Epoch 43/50\n","----------\n","train Loss: 0.0035 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0057 Acc: 0.8113 F1: 0.8329\n","\n","Epoch 44/50\n","----------\n","train Loss: 0.0035 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0059 Acc: 0.8113 F1: 0.8329\n","\n","Epoch 45/50\n","----------\n","train Loss: 0.0035 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0055 Acc: 0.8085 F1: 0.8308\n","\n","Epoch 46/50\n","----------\n","train Loss: 0.0035 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0057 Acc: 0.8085 F1: 0.8308\n","\n","Epoch 47/50\n","----------\n","train Loss: 0.0035 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0054 Acc: 0.8099 F1: 0.8319\n","\n","Epoch 48/50\n","----------\n","train Loss: 0.0035 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0056 Acc: 0.8070 F1: 0.8298\n","\n","Epoch 49/50\n","----------\n","train Loss: 0.0035 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0055 Acc: 0.8155 F1: 0.8352\n","\n","Epoch 50/50\n","----------\n","train Loss: 0.0035 Acc: 0.9864 F1: 0.9870\n","val Loss: 0.0058 Acc: 0.8155 F1: 0.8352\n","\n","Training complete in 25m 48s\n","Best val F1: 0.835443\n"]},{"data":{"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch_avg_acc_train</td><td>▁▄▅▆▇▇▇█████████████████████████████████</td></tr><tr><td>epoch_avg_acc_val</td><td>▁▃▃▅▇▆▆█▇▆▆▇▇▇▇▆▇▇▇██▅██▇█▇▇▆▇▅██▇▇▇▇▇▇█</td></tr><tr><td>epoch_avg_loss_train</td><td>█▇▆▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch_avg_loss_val</td><td>█▇▆▅▃▃▃▂▂▂▂▂▃▂▂▂▂▂▂▂▂▄▂▁▂▂▁▂▂▂▄▂▂▂▂▃▂▁▁▂</td></tr><tr><td>epoch_f1</td><td>▁▄▄▆▇▇▆██▇▇▇▇▇▆▆▇▇▇██▆██▇█▇▇▇▇▆███████▇█</td></tr><tr><td>global_step</td><td>▆▄▇▃▁▅█▄▂▅▁▇▂▆▂▇▃▇▅█▄▇▅▁▅▂▆▂▅▃▇▂█▄▇▃▁▅█▄</td></tr><tr><td>step_train_loss</td><td>█▇▆▅▄▄▃▂▂▂▂▂▂▂▂▂▂▂▂▃▁▁▂▁▁▁▂▂▁▁▁▁▁▁▁▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>50</td></tr><tr><td>epoch_avg_acc_train</td><td>0.98637</td></tr><tr><td>epoch_avg_acc_val</td><td>0.81549</td></tr><tr><td>epoch_avg_loss_train</td><td>0.00348</td></tr><tr><td>epoch_avg_loss_val</td><td>0.00578</td></tr><tr><td>epoch_f1</td><td>0.83522</td></tr><tr><td>global_step</td><td>22</td></tr><tr><td>step_train_loss</td><td>0.32459</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Synced <strong style=\"color:#cdcd00\">FT_3_fullEkman_dreddit_ft_lr0.00005_emb_9_unfreeze</strong>: <a href=\"https://wandb.ai/maslenkovas/nlp-project/runs/2j797yg5\" target=\"_blank\">https://wandb.ai/maslenkovas/nlp-project/runs/2j797yg5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20220428_203232-2j797yg5/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["import wandb\n","\n","#  Start a new run\n","wandb.init(project=\"nlp-project\", name='FT_3_fullEkman_dreddit_ft_lr0.00005_emb_9_unfreeze')\n","\n","# Train and evaluate\n","model_ft, hist = train_model(model_ft, dataloaders_dict, loss_fn, optimizer_ft, num_epochs=50, checkpoint_path=DREDDIT_FT_MODEL_PATH)\n","\n","wandb.finish()"]},{"cell_type":"code","execution_count":85,"metadata":{"executionInfo":{"elapsed":530,"status":"ok","timestamp":1650376384427,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"boWKOCWY3-lS"},"outputs":[],"source":["def load_checkpoint(load_path, model, optimizer):\n","  if load_path==None: return\n","\n","  state_dict = torch.load(load_path, map_location=device)\n","  print(f'Model loaded from <== {load_path}')\n","\n","  model.load_state_dict(state_dict['state_dict'])\n","  optimizer.load_state_dict(state_dict['optimizer'])\n","\n","  return state_dict['valid_loss_min']\n"]},{"cell_type":"markdown","metadata":{"id":"ml1xjochNRLe"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["from sklearn.metrics import classification_report\n","\n","def evaluate(model, test_data, use_cuda=False):\n","\n","    test = Stress_FT_Dataset(test_data, tokenizer, MAX_LEN)\n","\n","    test_dataloader = torch.utils.data.DataLoader(test, batch_size=8)\n","\n","    # use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda==True else \"cpu\")\n","    model = model.to(device)\n","    stacked_labels = torch.tensor([])\n","    stacked_preds = torch.tensor([])\n","\n","    if use_cuda:\n","\n","        model = model.cuda()\n","\n","    total_acc_test = 0\n","    with torch.no_grad():\n","\n","        for batch_idx, data in enumerate(test_dataloader):\n","\n","            ids = data['ids'].to(device, dtype = torch.long)\n","            mask = data['mask'].to(device, dtype = torch.long)\n","            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n","            targets = data['targets'].to(device, dtype = torch.int)\n","\n","            output = model(ids, mask, token_type_ids)\n","            output = torch.sigmoid(output).cpu()\n","            preds = torch.tensor(np.array(output.detach().numpy()) > 0.5).to(device, dtype = torch.int)\n","            preds = preds.argmax(dim=1)\n","            acc = (preds == targets).sum().item()\n","            total_acc_test += acc\n","            stacked_labels = torch.cat([stacked_labels, targets])\n","            stacked_preds = torch.cat([stacked_preds, preds])\n","    \n","    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n","    print(classification_report(stacked_labels, stacked_preds, output_dict=False))\n","\n","    return classification_report(stacked_labels, stacked_preds, output_dict=True)\n","    "]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["'/home/svetlanamaslenkova/Documents/nlp_project/checkpoints/full_ekman_ft_dreddit_ft.pt'"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["DREDDIT_FT_MODEL_PATH"]},{"cell_type":"code","execution_count":115,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model loaded from <== /home/svetlanamaslenkova/Documents/nlp_project/checkpoints/4cat_ft_dreddit_ft.pt\n"]},{"data":{"text/plain":["0.008365489542484283"]},"execution_count":115,"metadata":{},"output_type":"execute_result"}],"source":["load_checkpoint(DREDDIT_FT_MODEL_PATH, model_ft, optimizer_ft)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["device = 'cpu'\n","print(device)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["model_ft = model_ft.to(device)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"xTS8a-ksD2gZ"},"outputs":[],"source":["test_data = pd.read_csv(TEST_DATA_PATH)[['text', 'label']]\n","\n","test_set = Stress_FT_Dataset(test_data, tokenizer, MAX_LEN)\n","test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=16)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20659,"status":"ok","timestamp":1649589793883,"user":{"displayName":"Svetlana Maslenkova","userId":"16443472050162924369"},"user_tz":-240},"id":"PpFpCJIZNcEX","outputId":"670146fa-b68c-425f-a926-108adb299d31"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy:  0.779\n","              precision    recall  f1-score   support\n","\n","         0.0       0.80      0.73      0.76       346\n","         1.0       0.76      0.83      0.79       369\n","\n","    accuracy                           0.78       715\n","   macro avg       0.78      0.78      0.78       715\n","weighted avg       0.78      0.78      0.78       715\n","\n"]},{"data":{"text/plain":["{'0.0': {'precision': 0.7974683544303798,\n","  'recall': 0.7283236994219653,\n","  'f1-score': 0.7613293051359517,\n","  'support': 346},\n"," '1.0': {'precision': 0.7644110275689223,\n","  'recall': 0.8265582655826558,\n","  'f1-score': 0.7942708333333333,\n","  'support': 369},\n"," 'accuracy': 0.779020979020979,\n"," 'macro avg': {'precision': 0.7809396909996511,\n","  'recall': 0.7774409825023105,\n","  'f1-score': 0.7778000692346425,\n","  'support': 715},\n"," 'weighted avg': {'precision': 0.7804079997284529,\n","  'recall': 0.779020979020979,\n","  'f1-score': 0.7783298980098451,\n","  'support': 715}}"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["evaluate(model_ft, test_data)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPgGWPCKwsE6qJbtOPwBqzS","mount_file_id":"16qhfIDe8sxAPm-U6wh212Y4x1q03CP_C","name":"dreddit_ft.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01005edc168f4540b7e46c7907e80c67":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b0ed811216543588b38c137c57b3331":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe54b5efc1094e8aa48940a111abcdc8","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0f5e55da36c471d91d98a96c6f83837","value":231508}},"0f731478802344a2b9c3962de8184b8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1245e658e82b4d7f8d281b1582089de6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15ef4a18ff8749b3931af3855934268e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"186c1f8bbbe24219972443bb2a0f262f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ff0a0a64a6d4c33aad012a633857d07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29d4de607d0649c4a26c61a14bfd6b85","placeholder":"​","style":"IPY_MODEL_15ef4a18ff8749b3931af3855934268e","value":"Downloading: 100%"}},"21708d51fbbf4664b43daee248f1c2b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25bd4f7f006246d3b5ceccd15080b5e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29d4de607d0649c4a26c61a14bfd6b85":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d4e7d02f6a949b6a054304affbbceb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_fafa7f1d1f6a431a8800d71a58225437","IPY_MODEL_8a21bb5d6544469699db4688c79b8675"],"layout":"IPY_MODEL_819bac1a67724f3981e558266864aa80"}},"316fae4b9cf74be693eb4c49c64d6bdf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_01005edc168f4540b7e46c7907e80c67","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66e6b4fd40ea4b8583f72a52a515d98d","value":28}},"34ca726ad7104c88ad979a79a889cca5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5d6e0e75db74ef8a89a9f49ed44e19d","placeholder":"​","style":"IPY_MODEL_4bd2c1e3293c43908f6546007511ea7f","value":" 226k/226k [00:00&lt;00:00, 1.47MB/s]"}},"391e7c39a37341118b86821139598815":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1ff0a0a64a6d4c33aad012a633857d07","IPY_MODEL_316fae4b9cf74be693eb4c49c64d6bdf","IPY_MODEL_5d147280bd0741398aa0119eada21d07"],"layout":"IPY_MODEL_eb2e425ab2de4e7a9e0acb5dd8596f46"}},"4bd2c1e3293c43908f6546007511ea7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c9bda6fbde647bf997f508b76199b9d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5387bc93b7c24dc38c8fb27e19694983":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d93692a3055e43e2a9e0edba051196a2","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9925a1b9341a41ba8cf4cea751de3a7f","value":570}},"5d147280bd0741398aa0119eada21d07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9193860e7e9a484982d2f3b45ed534e6","placeholder":"​","style":"IPY_MODEL_8827f1e845a04a2e8295a3d39c08cfc7","value":" 28.0/28.0 [00:00&lt;00:00, 878B/s]"}},"63e7ec0056354dd892bbe31f6aa9312f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66e6b4fd40ea4b8583f72a52a515d98d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6882de94e1ab42a38e1761bb8838367c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6aa7334d9d8d41078d005aef609f7620":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79231d87f06544bb9f46e58312c91094":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"819bac1a67724f3981e558266864aa80":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8827f1e845a04a2e8295a3d39c08cfc7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a21bb5d6544469699db4688c79b8675":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_25bd4f7f006246d3b5ceccd15080b5e3","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9a11bc46c96a446587b672c206e248b4","value":1}},"905691cc49b94b349248fd2807862d63":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9193860e7e9a484982d2f3b45ed534e6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94f8545622c24e30bcc7bc9f69b01a9b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96bca789e402455eae5b5a0d8d6fb7a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9925a1b9341a41ba8cf4cea751de3a7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a11bc46c96a446587b672c206e248b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aae4e04292b24eb3945bfdb2c861137b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_905691cc49b94b349248fd2807862d63","placeholder":"​","style":"IPY_MODEL_0f731478802344a2b9c3962de8184b8b","value":" 570/570 [00:00&lt;00:00, 13.6kB/s]"}},"af08011d784943de8effbabe64f7b697":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5bfa525f3a54e1e9d1b3ec0d35c7a22":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8df008871184250a97b5a125784e05a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c086868fdf154110b8c2db89ea369bec","IPY_MODEL_5387bc93b7c24dc38c8fb27e19694983","IPY_MODEL_aae4e04292b24eb3945bfdb2c861137b"],"layout":"IPY_MODEL_eff42d7ed4c64a6baf5362580a57d687"}},"c086868fdf154110b8c2db89ea369bec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5bfa525f3a54e1e9d1b3ec0d35c7a22","placeholder":"​","style":"IPY_MODEL_63e7ec0056354dd892bbe31f6aa9312f","value":"Downloading: 100%"}},"c79c1c688b3c4f7389cf76a934a82378":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f204f4c79e254cbaa96f05c9b018fa67","IPY_MODEL_0b0ed811216543588b38c137c57b3331","IPY_MODEL_34ca726ad7104c88ad979a79a889cca5"],"layout":"IPY_MODEL_6882de94e1ab42a38e1761bb8838367c"}},"d93692a3055e43e2a9e0edba051196a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db48260bcac44a29b740eaf5fa875031":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6aa7334d9d8d41078d005aef609f7620","placeholder":"​","style":"IPY_MODEL_96bca789e402455eae5b5a0d8d6fb7a1","value":"0.378 MB of 0.378 MB uploaded (0.000 MB deduped)\r"}},"db7763e7abe841e3a4ef3a1e957b7f07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_db48260bcac44a29b740eaf5fa875031","IPY_MODEL_df71124fd040499b8117c8bcba05cc82"],"layout":"IPY_MODEL_1245e658e82b4d7f8d281b1582089de6"}},"df71124fd040499b8117c8bcba05cc82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_186c1f8bbbe24219972443bb2a0f262f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c9bda6fbde647bf997f508b76199b9d","value":1}},"e0f5e55da36c471d91d98a96c6f83837":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5d6e0e75db74ef8a89a9f49ed44e19d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb2e425ab2de4e7a9e0acb5dd8596f46":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eff42d7ed4c64a6baf5362580a57d687":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f204f4c79e254cbaa96f05c9b018fa67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94f8545622c24e30bcc7bc9f69b01a9b","placeholder":"​","style":"IPY_MODEL_21708d51fbbf4664b43daee248f1c2b7","value":"Downloading: 100%"}},"fafa7f1d1f6a431a8800d71a58225437":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af08011d784943de8effbabe64f7b697","placeholder":"​","style":"IPY_MODEL_79231d87f06544bb9f46e58312c91094","value":"1.157 MB of 1.157 MB uploaded (0.000 MB deduped)\r"}},"fe54b5efc1094e8aa48940a111abcdc8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
